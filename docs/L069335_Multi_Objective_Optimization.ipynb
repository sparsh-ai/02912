{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L069335 | Multi-Objective Optimization",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/iC3dFD5pV5oZ1v7lZQVB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt7kj-XtqS5T"
      },
      "source": [
        "# Multi-Objective Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tkINLZZqmfB"
      },
      "source": [
        "Many people may not realize that Multi Objective Problems (MOP) could be general in our life and society. Every day we are making decisions trying to compromise among different objectives. If you were a car buyer, you want to lower price and gas consumption, and higher level of comfort and performance. With limited budget, these objectives are conflict each other. You need to balance between lower price or gas consumption and comfort or performance. On the society level, the central bank’s monetary policy needs to balance among inflation rate, unemployment rate, trade deficit and other economic factors. Lower interest rate may reduce the unemployment but may increase the risk of inflation at same time. We can find similar situations in other areas such as engineering and communication designs. In each situation, the decision maker (DM) wants to optimize more than one objective, which are conflict each other in most of cases.\n",
        "\n",
        "### Problem formulation\n",
        "\n",
        "A multi-objective optimization problem is an optimization problem in which several possibly conflicting objectives are being optimized simultaneously. It can be defined as follows:\n",
        "\n",
        "$$\\min_{w \\in R^D} L(w) = \\min_{w \\in R^D} \\bigg| L_1(w), L_2(w),\\dots,L_n(w) \\bigg|^{}_{n \\times 1}\n",
        "$$\n",
        "\n",
        "where $n$ is the number of objectives to optimize, $w$ the model parameters, $D$ is the total number of parameters, $L_i:R^D \\rightarrow R,\\ i=1,\\dots,n$, $L_i$ is a single objective loss function, and $L$ is the multi-objective loss function. Operator $\\min$ represents the operation of minimization of all objectives simultaneously. This is not a limiting factor, because, without loss of generality, any maximization problem can be transformed into a minimization problem.\n",
        "\n",
        "In case that a gradient-based optimization algorithm is applied, the gradient of every constituent loss function $\\nabla_wL_i(w)$ has to be a Lipschitz continuous function (Murphy, 2013).\n",
        "\n",
        "### Scenario: Optimal fruit choice\n",
        "\n",
        "Let's understand with an example. Imagine you want to eat a fruit and you have conditions - the fruit should be healthy as well as tasty. Based on your knowledge, you draw the following diagram to decide which fruit to eat:\n",
        "\n",
        "<p><center><figure><img src='_images/L069335_1.png'><figcaption>[source](https://www.alexirpan.com/public/fruit-opinion/xkcdfruit.png)</figcaption></figure></center></p>\n",
        "\n",
        "So which one is the best to eat? The answer is that there is no single optimal choice here but three - Peaches, Strawberries, and Seedless grapes. These 3 fruits are at the Pareto Front (don't worry, we are going to learn this concept) and called non-dominated and therefore optimal choices.\n",
        "\n",
        "### Scenario: Cement factory\n",
        "\n",
        "Let's say we run a cement factory and looking to optimize our profits. But as per regulations and ethics, we also need to take care of health impacts to nearby communities. So let's understand how we can formulate this situation as MOO. Objective 1 could be to maximize production to maximize profit. Objective 2 could be to minimize hazardous wastes to protect health of nearby communities. How to solve the contradiction between objectives? - we can do that by compromising. Given these objectives, one way to formulate our goal is ***Max(Profit) s.t. Produced hazards ≤ Max allowable value.*** We can alternatively formulate our goal as ***Max(Profit/Hazards)***.\n",
        "\n",
        "### Scenario: Accuracy vs speed tradeoff\n",
        "\n",
        "We can frame the multi-objective optimization problem as a search for optimal tradeoffs. Let’s imagine that we really care about exactly two objectives: predictive accuracy, and the speed at which we can make a prediction.\n",
        "\n",
        "Unfortunately, these things are likely to be in tension. It may be possible to construct a very accurate classifier by using extremely large models, or stacking several ML algorithms, or by performing many complex feature transformations. All of these things increase the computation necessary to make a prediction, and thus slow us down.\n",
        "\n",
        "Imagine we randomly sampled hyperparameter configurations and measured the speed and accuracy of the resulting models. We would surely find some configurations that result in algorithms being both slower and less accurate than others. Speaking technically, if one point—call it `A`—is better than another point—`B`—in one dimension, and at least as good in all other dimensions, we say `A` *dominates* `B`. We’d never want to deploy dominated models, since there are other models that are strictly better in both the optimization objectives.\n",
        "\n",
        "<p><center><figure><img src='_images/L069335_2.png'><figcaption>As we try different hyperparameter configurations, we’ll find that the resultant models represent different accuracy-speed trade offs. We can visualize each model as a point in the trade off space.</figcaption></figure></center></p>\n",
        "\n",
        "It’s possible we’d find one point that maximizes both the accuracy and speed of our predictions. In practice, this is unlikely. We might improve accuracy by using deeper trees in a random forest, but deeper trees also take longer to evaluate, so we have traded off some speed for accuracy.\n",
        "\n",
        "Eventually, we’ll discern an edge in the accuracy-speed tradeoff space, where we cannot find a hyperparameter combination that leads to an improvement in one direction without a negative impact on the other. This edge is called the *Pareto frontier*, and allows us to make a quantitative tradeoff between our optimization objectives. The Pareto frontier is constructed from the set of non-dominated points, and choosing any one of them gives us our exact accuracy/speed tradeoff.\n",
        "\n",
        "<p><center><figure><img src='_images/L069335_3.png'><figcaption>As we try different hyperparameter configurations, we’ll find that the resultant models represent different accuracy-speed trade offs. We can visualize each model as a point in the trade off space.</figcaption></figure></center></p>\n",
        "\n",
        "Ultimately, a deployed ML system will be trained with a single hyperparameter combination, and we must choose a single *point* in the accuracy-speed plane. The Pareto frontier allows us to present a decision maker with a host of models, some maximizing accuracy, others maximizing speed, and the entire spectrum in between.\n",
        "\n",
        "How do we find this frontier? We could construct it with a dense random sampling of the hyperparameter search space. This risks being inefficient. We’d like to spend as little time as possible sampling configurations that aren’t likely to expand the Pareto frontier. Every sample on the frontier is useful, because they let us trade off accuracy and speed in a new combination. Samples inside the frontier end up being useless."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV1ePCNSroMk"
      },
      "source": [
        "```{tableofcontents}\n",
        "```"
      ]
    }
  ]
}